\subsubsection{Problem definition for Time-series Forecasting} \label{sec:time-series_problem_definition}
Since time is inherently continuous, these series are represented through discrete time steps, determined by a chosen sampling frequency, which can range from milliseconds to hours. For simplicity we assume that the entire dataset $X$ is discretized evenly in the rest of the paper if not explicitly specified. The historical time range, comprising $H$ steps, is defined as the set of observations $obs = \left\{t \in \mathbb{Z} \mid -H < t \leq 0\right\}$, while the future range, spanning $F$ steps, is denoted as the targets $tar = \left\{t \in \mathbb{Z} \mid 0 < t \leq F\right\}$. Consequently, historical data can be represented as $X_{obs} \in \mathbb{R}^{d \times H}$, and the target forecast data as $X_{tar} \in \mathbb{R}^{d \times F}$, where $d$ indicates the number of distinct features. A time-series is classified as univariate when $d = 1$ as illustrated in \autoref{fig:time-series-univariate}, and as multivariate when $d > 1$. In this context, a specific value at time step $t$ and feature $i$ from the time-series can be defined as $x_{i,t}$, where $i \in \left\{1 \dots d\right\}$ and $t \in \left\{-H, \ldots, F\right\}$ or as $x_t$ when talking about the entire value vector at the time step.

